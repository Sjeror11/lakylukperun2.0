# ğŸŒ RozhranÃ­ WebovÃ½ch Dat (Web Data Interface)

## ğŸ“ PÅ™ehled

`WebDataInterface` (`src/interfaces/web_data.py`) definuje standardnÃ­ kontrakt pro zÃ­skÃ¡vÃ¡nÃ­ a potenciÃ¡lnÄ› parsovÃ¡nÃ­ dat z externÃ­ch webovÃ½ch zdrojÅ¯, jako jsou finanÄnÃ­ zpravodajskÃ© weby, ekonomickÃ© kalendÃ¡Å™e nebo agregÃ¡tory sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­.

## ğŸ¯ ÃšÄel

*   Abstrahovat proces zÃ­skÃ¡vÃ¡nÃ­ informacÃ­ z rÅ¯znÃ½ch webovÃ½ch zdrojÅ¯ (napÅ™. scraping webovÃ½ch strÃ¡nek, volÃ¡nÃ­ specifickÃ½ch zpravodajskÃ½ch API).
*   Poskytnout konzistentnÃ­ zpÅ¯sob, jak mohou sluÅ¾by (primÃ¡rnÄ› `AIService`) pÅ™istupovat k externÃ­m informacÃ­m, kterÃ© by mohly ovlivnit obchodnÃ­ rozhodnutÃ­ (napÅ™. titulky zprÃ¡v, skÃ³re sentimentu, nadchÃ¡zejÃ­cÃ­ ekonomickÃ© udÃ¡losti).
*   UmoÅ¾nit pÅ™idÃ¡vÃ¡nÃ­ novÃ½ch zdrojÅ¯ webovÃ½ch dat vytvoÅ™enÃ­m novÃ½ch implementacÃ­ rozhranÃ­.
*   Usnadnit testovÃ¡nÃ­ povolenÃ­m mock (faleÅ¡nÃ½ch) implementacÃ­, kterÃ© vracejÃ­ vzorovÃ¡ webovÃ¡ data bez provÃ¡dÄ›nÃ­ Å¾ivÃ½ch HTTP poÅ¾adavkÅ¯.

## ğŸ”‘ KlÃ­ÄovÃ© Metody (KoncepÄnÃ­)

`WebDataInterface` mÅ¯Å¾e definovat metody jako:

*   **`fetch_news(query: str, max_results: int)`:** ZÃ­skÃ¡ nedÃ¡vnÃ© zpravodajskÃ© ÄlÃ¡nky souvisejÃ­cÃ­ s konkrÃ©tnÃ­m dotazem (napÅ™. symbol akcie, trÅ¾nÃ­ sektor). VracÃ­ seznam zpravodajskÃ½ch poloÅ¾ek (napÅ™. titulky, shrnutÃ­, URL, ÄasovÃ¡ razÃ­tka).
*   **`fetch_economic_events(date_range: Tuple[date, date])`:** NaÄte naplÃ¡novanÃ© ekonomickÃ© udÃ¡losti (napÅ™. zveÅ™ejnÄ›nÃ­ HDP, rozhodnutÃ­ o ÃºrokovÃ½ch sazbÃ¡ch) v danÃ©m ÄasovÃ©m rozmezÃ­.
*   **`fetch_sentiment(symbol: str)`:** PokusÃ­ se zÃ­skat skÃ³re sentimentu nebo souvisejÃ­cÃ­ komentÃ¡Å™e pro specifickÃ½ obchodnÃ­ symbol z nakonfigurovanÃ©ho zdroje.

PÅ™esnÃ© metody zÃ¡visÃ­ na specifickÃ½ch potÅ™ebÃ¡ch `AIService` a integrovanÃ½ch zdrojÃ­ch dat.

## âš™ï¸ Implementace

KonkrÃ©tnÃ­ implementace mohou zahrnovat:

*   `NewsAPIFetcher`: PouÅ¾Ã­vÃ¡ komerÄnÃ­ sluÅ¾bu News API.
*   `WebScraper`: Implementuje logiku pro scraping specifickÃ½ch finanÄnÃ­ch webovÃ½ch strÃ¡nek (vyÅ¾aduje peÄlivÃ© zachÃ¡zenÃ­ s podmÃ­nkami sluÅ¾by webovÃ½ch strÃ¡nek a potenciÃ¡lnÃ­mi zmÄ›nami struktury).
*   `MockWebData`: VracÃ­ pÅ™eddefinovanÃ¡ vzorovÃ¡ data zprÃ¡v nebo udÃ¡lostÃ­ pro testovÃ¡nÃ­.

`OrchestrationDaemon` nebo `AIService` by vybraly a instanciovaly pÅ™Ã­sluÅ¡nou implementaci.

## âš™ï¸ Konfigurace

Implementace mohou vyÅ¾adovat:

*   API klÃ­Äe pro komerÄnÃ­ poskytovatele dat.
*   URL adresy webovÃ½ch strÃ¡nek pro scraping.
*   Konfiguraci pro logiku parsovÃ¡nÃ­.

Tyto by byly typicky uloÅ¾eny v souboru `.env`.

## ğŸ”— KlÃ­ÄovÃ© Interakce

*   **`AIService` ğŸ¤–:** PravdÄ›podobnÄ› primÃ¡rnÃ­ konzument, poÅ¾adujÃ­cÃ­ externÃ­ data k obohacenÃ­ kontextu poskytovanÃ©ho LLM pro analÃ½zu.
*   **`config.py` âš™ï¸:** ÄŒte API klÃ­Äe nebo URL potÅ™ebnÃ© pro implementaci.
*   **ExternÃ­ Knihovny:** MÅ¯Å¾e pouÅ¾Ã­vat knihovny jako `requests`, `beautifulsoup4` (pro scraping) nebo specifickÃ© klientskÃ© knihovny API.
*   **`logger.py` ğŸ“:** Loguje pokusy o zÃ­skÃ¡nÃ­ webovÃ½ch dat a jejich vÃ½sledky.
